{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discrete-Time Black Scholes\n",
    "Welcome to your 1st assignment in Reinforcement Learning in Finance. This exercise will introduce Black-Scholes model as viewed through the lens of pricing an option as discrete-time replicating portfolio of stock and bond.\n",
    "\n",
    "**Instructions:**\n",
    "- You will be using Python 3.\n",
    "- Avoid using for-loops and while-loops, unless you are explicitly told to do so.\n",
    "- Do not modify the (# GRADED FUNCTION [function name]) comment in some cells. Your work would not be graded if you change this. Each cell containing that comment should only contain one function.\n",
    "- After coding your function, run the cell right below it to check if your result is correct.\n",
    "\n",
    "\n",
    "Let's get started!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## About iPython Notebooks ##\n",
    "\n",
    "iPython Notebooks are interactive coding environments embedded in a webpage. You will be using iPython notebooks in this class. You only need to write code between the ### START CODE HERE ### and ### END CODE HERE ### comments. After writing your code, you can run the cell by either pressing \"SHIFT\"+\"ENTER\" or by clicking on \"Run Cell\" (denoted by a play symbol) in the upper bar of the notebook. \n",
    "\n",
    "We will often specify \"(≈ X lines of code)\" in the comments to tell you about how much code you need to write. It is just a rough estimate, so don't feel bad if your code is longer or shorter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from numpy.random import standard_normal, seed\n",
    "\n",
    "import scipy.stats as stats\n",
    "from scipy.stats import norm\n",
    "\n",
    "import datetime \n",
    "import time\n",
    "import bspline\n",
    "import bspline.splinelab as splinelab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The Black-Scholes prices\n",
    "def bs_put(t, S0, K, r, sigma, T):\n",
    "    d1 = (np.log(S0/K) + (r + 1/2 * sigma**2) * (T-t)) / sigma / np.sqrt(T-t)\n",
    "    d2 = (np.log(S0/K) + (r - 1/2 * sigma**2) * (T-t)) / sigma / np.sqrt(T-t)\n",
    "    price = K * np.exp(-r * (T-t)) * norm.cdf(-d2) - S0 * norm.cdf(-d1)\n",
    "    return price\n",
    "\n",
    "def bs_call(t, S0, K, r, sigma, T):\n",
    "    d1 = (np.log(S0/K) + (r + 1/2 * sigma**2) * (T-t)) / sigma / np.sqrt(T-t)\n",
    "    d2 = (np.log(S0/K) + (r - 1/2 * sigma**2) * (T-t)) / sigma / np.sqrt(T-t)\n",
    "    price = S0 * norm.cdf(d1) - K * np.exp(-r * (T-t)) * norm.cdf(d2)\n",
    "    return price\n",
    "\n",
    "def d1(S0, K, r, sigma, T):\n",
    "    return (np.log(S0/K) + (r + sigma**2 / 2) * T)/(sigma * np.sqrt(T))\n",
    " \n",
    "def d2(S0, K, r, sigma, T):\n",
    "    return (np.log(S0 / K) + (r - sigma**2 / 2) * T) / (sigma * np.sqrt(T))\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simulate $N_{MC}$ stock price sample paths with $T$ steps by the classical Black-Sholes formula.\n",
    "\n",
    "$$dS_t=\\mu S_tdt+\\sigma S_tdW_t\\quad\\quad S_{t+1}=S_te^{\\left(\\mu-\\frac{1}{2}\\sigma^2\\right)\\Delta t+\\sigma\\sqrt{\\Delta t}Z}$$\n",
    "\n",
    "where $Z$ is a standard normal random variable.\n",
    "\n",
    "MC paths are simulated by GeneratePaths() method of DiscreteBlackScholes class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1\n",
    "\n",
    "\n",
    "Class DiscreteBlackScholes implements the above calculations with class variables to math symbols mapping of:\n",
    "\n",
    "$$\\Delta S_t=S_{t+1} - e^{-r\\Delta t} S_t\\space \\quad t=T-1,...,0$$\n",
    " \n",
    "**Instructions:**\n",
    "Some portions of code in DiscreteBlackScholes have bee taken out. You are to implement the missing portions of code in DiscreteBlackScholes class.\n",
    "\n",
    "$$\\Pi_t=e^{-r\\Delta t}\\left[\\Pi_{t+1}-u_t \\Delta S_t\\right]\\quad t=T-1,...,0$$\n",
    "\n",
    "- implement DiscreteBlackScholes.function_A_vec() method\n",
    "$$A_{nm}^{\\left(t\\right)}=\\sum_{k=1}^{N_{MC}}{\\Phi_n\\left(X_t^k\\right)\\Phi_m\\left(X_t^k\\right)\\left(\\Delta\\hat{S}_t^k\\right)^2}\\quad\\quad$$ \n",
    "\n",
    "- implement DiscreteBlackScholes.function_B_vec() method\n",
    "$$B_n^{\\left(t\\right)}=\\sum_{k=1}^{N_{MC}}{\\Phi_n\\left(X_t^k\\right)\\left[\\hat\\Pi_{t+1}^k\\Delta\\hat{S}_t^k+\\frac{1}{2\\gamma\\lambda}\\Delta S_t^k\\right]}$$\n",
    "- implement DiscreteBlackScholes.gen_paths() method using the following relation:\n",
    "$$S_{t+1}=S_te^{\\left(\\mu-\\frac{1}{2}\\sigma^2\\right)\\Delta t+\\sigma\\sqrt{\\Delta t}Z}$$\n",
    "where $Z \\sim N(0,1)$\n",
    "- implement parts of DiscreteBlackScholes.roll_backward()\n",
    "    - DiscreteBlackScholes.bVals corresponds to $B_t$ and is computed as $$B_t = e^{-r\\Delta t}\\left[B_{t+1} + (u_{t+1} - u_t)S_{t+1}\\right]\\quad t=T-1,...,0$$\n",
    "    \n",
    "DiscreteBlackScholes.opt_hedge corresponds to $\\phi_t$ and is computed as \n",
    "     $$\\phi_t=\\mathbf A_t^{-1}\\mathbf B_t$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiscreteBlackScholes:\n",
    "    \"\"\"\n",
    "    Class implementing discrete Black Scholes\n",
    "    DiscreteBlackScholes is class for pricing and hedging under\n",
    "    the real-world measure for a one-dimensional Black-Scholes setting\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 s0,\n",
    "                 strike,\n",
    "                 vol,\n",
    "                 T,\n",
    "                 r,\n",
    "                 mu,\n",
    "                 numSteps,\n",
    "                 numPaths):\n",
    "        \"\"\"\n",
    "        :param s0: initial price of the underlying\n",
    "        :param strike: option strike\n",
    "        :param vol: volatility\n",
    "        :param T: time to maturity, in years\n",
    "        :param r: risk-free rate,\n",
    "        :param mu: real drift, asset drift\n",
    "        :param numSteps: number of time steps\n",
    "        :param numPaths: number of Monte Carlo paths\n",
    "        \"\"\"\n",
    "        self.s0 = s0\n",
    "        self.strike = strike\n",
    "        self.vol = vol\n",
    "        self.T = T\n",
    "        self.r = r\n",
    "        self.mu = mu\n",
    "        self.numSteps = numSteps\n",
    "        self.numPaths = numPaths\n",
    "\n",
    "        self.dt = self.T / self.numSteps  # time step\n",
    "        self.gamma = np.exp(-r * self.dt)  # discount factor for one time step, i.e. gamma in the QLBS paper\n",
    "\n",
    "        self.sVals = np.zeros((self.numPaths, self.numSteps + 1), 'float')  # matrix of stock values\n",
    "\n",
    "        # initialize half of the paths with stock price values ranging from 0.5 to 1.5 of s0\n",
    "        # the other half of the paths start with s0\n",
    "        half_paths = int(numPaths / 2)\n",
    "\n",
    "        if False:\n",
    "            # Grau (2010) \"Applications of Least-Squares Regressions to Pricing and Hedging of Financial Derivatives\"\n",
    "            self.sVals[:, 0] = (np.hstack((np.linspace(0.5 * s0, 1.5 * s0, half_paths),\n",
    "                                           s0 * np.ones(half_paths, 'float')))).T\n",
    "\n",
    "        self.sVals[:, 0] = s0 * np.ones(numPaths, 'float')\n",
    "        self.optionVals = np.zeros((self.numPaths, self.numSteps + 1), 'float')  # matrix of option values\n",
    "        self.intrinsicVals = np.zeros((self.numPaths, self.numSteps + 1), 'float')\n",
    "\n",
    "        self.bVals = np.zeros((self.numPaths, self.numSteps + 1), 'float')  # matrix of cash position values\n",
    "        self.opt_hedge = np.zeros((self.numPaths, self.numSteps + 1),\n",
    "                              'float')  # matrix of optimal hedges calculated from cross-sectional information F_t\n",
    "        self.X = None\n",
    "        self.data = None  # matrix of features, i.e. self.X as sum of basis functions\n",
    "        self.delta_S_hat = None\n",
    "\n",
    "        # coef = 1.0/(2 * gamma * risk_lambda)\n",
    "        # override it by zero to have pure risk hedge\n",
    "        self.coef = 0.\n",
    "\n",
    "    def gen_paths(self):\n",
    "        \"\"\"\n",
    "        A simplest path generator\n",
    "        \"\"\"\n",
    "        np.random.seed(42)\n",
    "        # Spline basis of order p on knots k\n",
    "\n",
    "        ### START CODE HERE ### (≈ 3-4 lines of code)\n",
    "        # self.sVals = your code goes here ...\n",
    "        for i in range(self.numPaths):\n",
    "            for j in range(self.numSteps):\n",
    "                self.sVals[i,j+1] = self.sVals[i,j] * np.exp((self.mu - 1/2 * (self.vol**2))*self.dt + self.vol * np.sqrt(self.dt) * np.random.normal())\n",
    "        ### END CODE HERE ###\n",
    "\n",
    "        # like in QLBS\n",
    "        delta_S = self.sVals[:, 1:] - np.exp(self.r * self.dt) * self.sVals[:, :self.numSteps]\n",
    "        self.delta_S_hat = np.apply_along_axis(lambda x: x - np.mean(x), axis=0, arr=delta_S)\n",
    "\n",
    "        # state variable\n",
    "        # delta_t here is due to their conventions\n",
    "        self.X = - (self.mu - 0.5 * self.vol ** 2) * np.arange(self.numSteps + 1) * self.dt + np.log(self.sVals)\n",
    "        X_min = np.min(np.min(self.X))\n",
    "        X_max = np.max(np.max(self.X))\n",
    "\n",
    "        print('X.shape = ', self.X.shape)\n",
    "        print('X_min, X_max = ', X_min, X_max)\n",
    "\n",
    "        p = 4  # order of spline (as-is; 3 = cubic, 4: B-spline?)\n",
    "        ncolloc = 12\n",
    "        tau = np.linspace(X_min, X_max, ncolloc)  # These are the sites to which we would like to interpolate\n",
    "        # k is a knot vector that adds endpoints repeats as appropriate for a spline of order p\n",
    "        # To get meaningful results, one should have ncolloc >= p+1\n",
    "        k = splinelab.aptknt(tau, p)\n",
    "        basis = bspline.Bspline(k, p)\n",
    "\n",
    "        num_basis = ncolloc  # len(k) #\n",
    "        self.data = np.zeros((self.numSteps + 1, self.numPaths, num_basis))\n",
    "\n",
    "        print('num_basis = ', num_basis)\n",
    "        print('dim self.data = ', self.data.shape)\n",
    "\n",
    "        # fill it, expand function in finite dimensional space\n",
    "        # in neural network the basis is the neural network itself\n",
    "        t_0 = time.time()\n",
    "        for ix in np.arange(self.numSteps + 1):\n",
    "            x = self.X[:, ix]\n",
    "            self.data[ix, :, :] = np.array([basis(el) for el in x])\n",
    "        t_end = time.time()\n",
    "        print('\\nTime Cost of basis expansion:', t_end - t_0, 'seconds')\n",
    "\n",
    "    def function_A_vec(self, t, reg_param=1e-3):\n",
    "        \"\"\"\n",
    "        function_A_vec - compute the matrix A_{nm} from Eq. (52) (with a regularization!)\n",
    "        Eq. (52) in QLBS Q-Learner in the Black-Scholes-Merton article\n",
    "\n",
    "        Arguments:\n",
    "        t - time index, a scalar, an index into time axis of data_mat\n",
    "        reg_param - a scalar, regularization parameter\n",
    "\n",
    "        Return:\n",
    "        - np.array, i.e. matrix A_{nm} of dimension num_basis x num_basis\n",
    "        \"\"\"\n",
    "        X_mat = self.data[t, :, :]\n",
    "        num_basis_funcs = X_mat.shape[1]\n",
    "        this_dS = self.delta_S_hat[:, t]\n",
    "        hat_dS2 = (this_dS ** 2).reshape(-1, 1)\n",
    "        A_mat = np.dot(X_mat.T, X_mat * hat_dS2) + reg_param * np.eye(num_basis_funcs)\n",
    "        return A_mat\n",
    "\n",
    "    def function_B_vec(self, t, Pi_hat):\n",
    "        \"\"\"\n",
    "        function_B_vec - compute vector B_{n} from Eq. (52) QLBS Q-Learner in the Black-Scholes-Merton article\n",
    "\n",
    "        Arguments:\n",
    "        t - time index, a scalar, an index into time axis of delta_S_hat\n",
    "        Pi_hat - pandas.DataFrame of dimension N_MC x T of portfolio values\n",
    "        Return:\n",
    "        B_vec - np.array() of dimension num_basis x 1\n",
    "        \"\"\"\n",
    "        tmp = Pi_hat * self.delta_S_hat[:, t] + self.coef * (np.exp((self.mu - self.r) * self.dt)) * self.sVals[:, t]\n",
    "        X_mat = self.data[t, :, :]  # matrix of dimension N_MC x num_basis\n",
    "\n",
    "        B_vec = np.dot(X_mat.T, tmp)\n",
    "        return B_vec\n",
    "\n",
    "    def seed_intrinsic(self, strike=None, cp='P'):\n",
    "        \"\"\"\n",
    "        initilaize option value and intrinsic value for each node\n",
    "        \"\"\"\n",
    "        if strike is not None:\n",
    "            self.strike = strike\n",
    "\n",
    "        if cp == 'P':\n",
    "            # payoff function at maturity T: max(K - S(T),0) for all paths\n",
    "            self.optionVals = np.maximum(self.strike - self.sVals[:, -1], 0).copy()\n",
    "            # payoff function for all paths, at all time slices\n",
    "            self.intrinsicVals = np.maximum(self.strike - self.sVals, 0).copy()\n",
    "        elif cp == 'C':\n",
    "            # payoff function at maturity T: max(S(T) -K,0) for all paths\n",
    "            self.optionVals = np.maximum(self.sVals[:, -1] - self.strike, 0).copy()\n",
    "            # payoff function for all paths, at all time slices\n",
    "            self.intrinsicVals = np.maximum(self.sVals - self.strike, 0).copy()\n",
    "        else:\n",
    "            raise Exception('Invalid parameter: %s'% cp)\n",
    "\n",
    "        self.bVals[:, -1] = self.intrinsicVals[:, -1]\n",
    "\n",
    "    def roll_backward(self):\n",
    "        \"\"\"\n",
    "        Roll the price and optimal hedge back in time starting from maturity\n",
    "        \"\"\"\n",
    "\n",
    "        for t in range(self.numSteps - 1, -1, -1):\n",
    "\n",
    "            # determine the expected portfolio value at the next time node\n",
    "            piNext = self.bVals[:, t+1] + self.opt_hedge[:, t+1] * self.sVals[:, t+1]\n",
    "            pi_hat = piNext - np.mean(piNext)\n",
    "\n",
    "            A_mat = self.function_A_vec(t)\n",
    "            B_vec = self.function_B_vec(t, pi_hat)\n",
    "            phi = np.dot(np.linalg.inv(A_mat), B_vec)\n",
    "            self.opt_hedge[:, t] = np.dot(self.data[t, :, :], phi)\n",
    "\n",
    "            ### START CODE HERE ### (≈ 1-2 lines of code)\n",
    "            # implement code to update self.bVals\n",
    "            # self.bVals[:,t] = your code goes here ....\n",
    "            self.bVals[:,t] = np.exp(-self.r*self.dt)*(self.bVals[:,t+1] + (self.opt_hedge[:,t+1] - self.opt_hedge[:,t])*self.sVals[:, t+1])\n",
    "\n",
    "\n",
    "            ### END CODE HERE ###\n",
    "\n",
    "        # calculate the initial portfolio value\n",
    "        initPortfolioVal = self.bVals[:, 0] + self.opt_hedge[:, 0] * self.sVals[:, 0]\n",
    "\n",
    "        # use only the second half of the paths generated with paths starting from S0\n",
    "        optionVal = np.mean(initPortfolioVal)\n",
    "        optionValVar = np.std(initPortfolioVal)\n",
    "        delta = np.mean(self.opt_hedge[:, 0])\n",
    "\n",
    "        return optionVal, delta, optionValVar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X.shape =  (100, 253)\n",
      "X_min, X_max =  3.907363551290155 5.128232848089766\n",
      "num_basis =  12\n",
      "dim self.data =  (253, 100, 12)\n",
      "\n",
      "Time Cost of basis expansion: 2.8954880237579346 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x109f50d68>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWkAAAEcCAYAAAAFlEU8AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x106a58dd8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "strike_k = 95\n",
    "test_vol = 0.2\n",
    "test_mu = 0.03\n",
    "dt = 0.01\n",
    "rfr = 0.05\n",
    "num_paths = 100\n",
    "num_periods = 252\n",
    "\n",
    "hMC = DiscreteBlackScholes(100, strike_k, test_vol, 1., rfr, test_mu, num_periods, num_paths)\n",
    "hMC.gen_paths()\n",
    "\n",
    "t = hMC.numSteps - 1\n",
    "piNext = hMC.bVals[:, t+1] + 0.1 * hMC.sVals[:, t+1]\n",
    "pi_hat = piNext - np.mean(piNext)\n",
    "\n",
    "A_mat = hMC.function_A_vec(t)\n",
    "B_vec = hMC.function_B_vec(t, pi_hat)\n",
    "phi = np.dot(np.linalg.inv(A_mat), B_vec)\n",
    "opt_hedge = np.dot(hMC.data[t, :, :], phi)\n",
    "\n",
    "# plot the results\n",
    "fig = plt.figure(figsize=(12,4))\n",
    "ax1 = fig.add_subplot(121)\n",
    "\n",
    "ax1.scatter(hMC.sVals[:,t], pi_hat)\n",
    "ax1.set_title(r'Expected $\\Pi_0$ vs. $S_t$')\n",
    "ax1.set_xlabel(r'$S_t$')\n",
    "ax1.set_ylabel(r'$\\Pi_0$')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.30582541,  0.65790247, -2.37085809,  5.93873493,  3.43877331,\n",
       "        3.76603526,  2.37584962, -1.18574813, -0.91891665,  0.47112895,\n",
       "        3.50365022, -2.22792045, -1.08849047,  0.09290477,  1.02795255,\n",
       "       -2.84613327, -2.28521445, -2.48180024, -0.1727714 ,  0.2242051 ,\n",
       "        0.54290355, -3.00426006, -1.99494316, -1.80932742,  0.3732366 ,\n",
       "       -2.30635046, -0.60600596, -1.43688403, -0.16705288, -0.04931523,\n",
       "       -0.60349502,  1.51995455,  0.30577794,  1.14153912,  2.1334825 ,\n",
       "       -1.2349866 , -0.59564637,  0.87279689, -1.89016841,  0.02420099,\n",
       "       -0.29781996, -1.5358432 , -1.31438917, -2.19656952, -0.04579728,\n",
       "       -0.76696689,  1.31339201, -0.84234588,  1.46200389, -2.20929917,\n",
       "        2.45521311,  0.33379629,  2.12878811,  0.44043398,  2.43620314,\n",
       "       -0.15128056,  1.196579  , -0.55828151,  1.09436979,  1.09538707,\n",
       "       -1.80134438,  0.4627116 , -0.05277691,  3.3732824 , -1.86600585,\n",
       "        1.36494261,  0.59161945,  0.06884503,  5.25877846,  0.8725059 ,\n",
       "       -1.00500654,  0.92325043,  1.49268232, -0.11829072, -0.56943942,\n",
       "       -2.01217773,  3.43234763,  0.28466107,  1.0413466 , -1.61263876,\n",
       "       -1.14593522, -1.86871438, -2.27695514,  2.24980683,  0.83722102,\n",
       "        0.15642648,  2.30161437, -0.9110928 , -4.97711597, -1.1984499 ,\n",
       "        1.61742815, -2.2728166 ,  1.38991804,  1.01331614, -2.88292219,\n",
       "        4.65255845, -3.18561652, -1.58012037, -0.87361145, -2.04072051])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### GRADED PART (DO NOT EDIT) ###\n",
    "pi_hat\n",
    "### GRADED PART (DO NOT EDIT) ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X.shape =  (50000, 7)\n",
      "X_min, X_max =  3.0081646479837856 6.397943802928419\n",
      "num_basis =  12\n",
      "dim self.data =  (7, 50000, 12)\n",
      "\n",
      "Time Cost of basis expansion: 38.373706102371216 seconds\n",
      "Option value =  13.10776532918034\n",
      "Option value variance =  5.195223258667358\n",
      "Option delta =  -0.35460754884841744\n",
      "BS value 13.145893900288087\n"
     ]
    }
   ],
   "source": [
    "# input parameters\n",
    "s0 = 100.0\n",
    "strike = 100.0\n",
    "r = 0.05\n",
    "mu = 0.07 # 0.05\n",
    "vol = 0.4\n",
    "T = 1.0\n",
    "\n",
    "# Simulation Parameters\n",
    "numPaths = 50000  # number of Monte Carlo trials\n",
    "numSteps = 6\n",
    "\n",
    "# create the class object\n",
    "hMC = DiscreteBlackScholes(s0, strike, vol, T, r, mu, numSteps, numPaths)\n",
    "\n",
    "# calculation\n",
    "hMC.gen_paths()\n",
    "hMC.seed_intrinsic()\n",
    "option_val, delta, option_val_variance = hMC.roll_backward()\n",
    "bs_call_value = bs_put(0, s0, K=strike, r=r, sigma=vol, T=T)\n",
    "print('Option value = ', option_val)\n",
    "print('Option value variance = ', option_val_variance)\n",
    "print('Option delta = ', delta)  \n",
    "print('BS value', bs_call_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13.10776532918034"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### GRADED PART (DO NOT EDIT) ###\n",
    "option_val\n",
    "### GRADED PART (DO NOT EDIT) ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X.shape =  (50000, 7)\n",
      "X_min, X_max =  3.0081646479837856 6.397943802928419\n",
      "num_basis =  12\n",
      "dim self.data =  (7, 50000, 12)\n",
      "\n",
      "Time Cost of basis expansion: 39.41750478744507 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 6.70326307,  8.59543726, 10.74614496, 13.1458939 , 15.78197485,\n",
       "       18.63949388])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "strikes = np.linspace(85, 110, 6)\n",
    "results = [None] * len(strikes)\n",
    "bs_prices = np.zeros(len(strikes))\n",
    "bs_deltas = np.zeros(len(strikes))\n",
    "numPaths = 50000\n",
    "hMC = DiscreteBlackScholes(s0, strike, vol, T, r, mu, numSteps, numPaths)\n",
    "hMC.gen_paths()\n",
    "for ix, k_strike in enumerate(strikes):\n",
    "    hMC.seed_intrinsic(k_strike)\n",
    "    results[ix] = hMC.roll_backward()\n",
    "    bs_prices[ix] = bs_put(0, s0, K=k_strike, r=r, sigma=vol, T=T)\n",
    "    bs_deltas[ix] = norm.cdf(d1(s0, K=k_strike, r=r, sigma=vol, T=T)) - 1\n",
    "bs_prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "mc_prices = np.array([x[0] for x in results])\n",
    "mc_deltas = np.array([x[1] for x in results])\n",
    "price_variances = np.array([x[-1] for x in results])\n",
    "prices_diff = mc_prices - bs_prices\n",
    "deltas_diff = mc_deltas - bs_deltas\n",
    "# price_variances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.03170513, -0.03237321, -0.03372986, -0.03812857, -0.03777805,\n",
       "       -0.03945185])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### GRADED PART (DO NOT EDIT) ###\n",
    "prices_diff\n",
    "### GRADED PART (DO NOT EDIT) ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.01502209, 0.01650454, 0.01751225, 0.01798299, 0.01853585,\n",
       "       0.01928136])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### GRADED PART (DO NOT EDIT) ###\n",
    "deltas_diff\n",
    "### GRADED PART (DO NOT EDIT) ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "coursera": {
   "course_slug": "machine-learning-in-finance",
   "graded_item_id": "jN2BT",
   "launcher_item_id": "VAp9I"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
